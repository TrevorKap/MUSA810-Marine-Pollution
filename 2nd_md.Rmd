---
title: "function_uo"
author: "Tianxiao"
date: "2024-02-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install.packages("remotes")
#remotes::install_github("IREA-CNR-MI/sprawl")

library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(classInt)
library(RCurl)
library(httr)
library(osmdata)
library(randomForest)
library(tidygraph)
library(XML)
library(neuralnet)
library(MASS)
library(tidymodels)
library(brms)
library(jsonlite)
library(QuickJSR)
library(rgdal)

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
source('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/function_UO.R')
st_c    <- st_coordinates
st_coid <- st_centroid
```

```{r load litter data}
# load litter data
litter <- read.csv('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/mdt-dataChennai.csv')

# data filter and projection transformation
litter_p <- litter%>%
  filter(master_material == 'PLASTIC')%>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")%>%
  st_transform('EPSG:32643')

# load boundary data
## ATTENTION! this part should be the boundry of YOUR CITY
chen_bdry <- st_read('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/gcc-divisions-latest.kml')
chen_bdry <- st_set_crs(chen_bdry, 4326)%>%
  st_transform('EPSG:32643')

temp_bd <- st_read('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/cma_layer.kml')

# create fishnet of city boundary
fishnet <- 
  st_make_grid(chen_bdry,
               cellsize = 500, 
               square = TRUE) %>%
  .[chen_bdry] %>%            
  st_sf() %>%
  mutate(uniqueID = 1:n())

# create fishnet(fn) variable of litter count
litter_net <- countfishnet(fishnet, litter_p)
```

## raster data
```{r load pop raster data}
# load raster data
## ATTENTION! you can download the data from facebook population link to your local place first
## AND, based on the lat & lon to choose the image you need, and the geometry info is in the name of file
img <- raster("https://github.com/TrevorKap/MUSA810-Marine-Pollution/raw/main/Data/rs_img/population_10_lon_80_general-v1.5.tif")
# p.s. this part is still the chennai boundary, why i load another one is the original one have incorrect z-dimention and can not be used as mask. 

tifCropped <- crop(img, extent(temp_bd)) # extract raster based on boundary
tifClipped <- mask(tifCropped, temp_bd) # clip the raster based on boundary
polys1 = rasterToPolygons(tifClipped) # convert raster to polygon (it will take some time, it's OK)
sf_object <- st_as_sf(polys1) 
temp <- as.data.frame(sf_object) # convert to sf dataframe
temp_sf <- st_as_sf(temp)
df_points <- st_centroid(temp_sf) # convert to point geometry
```

```{r create pop variable}
# convert projection
df_points <- df_points%>%
  st_transform('EPSG:32643')
joined_data <- st_join(fishnet, df_points) # merge fishnet and point dataset

# get the average pop of each fishnet cell 
avg_pop <- joined_data %>%
  group_by(uniqueID) %>%
  summarise(avg_pop = mean(Population.Count, na.rm = TRUE))

# data clean
avg_pop[is.na(avg_pop)] <- 0

# get the total pop of each fishnet cell 
sum_pop <- joined_data %>%
  group_by(uniqueID) %>%
  summarise(sum_pop = sum(Population.Count, na.rm = TRUE))
```

```{r pop varialbe viz}
# pop thing visualize
grid.arrange(
ggplot() +
      geom_sf(data = avg_pop, aes(fill = avg_pop), color = NA) +
      scale_fill_viridis() +
      labs(title = 'Average Pop for the fishnet') +
      mapTheme(),
ggplot() + 
      geom_sf(data = sum_pop, aes(fill = sum_pop), color = NA) +
      scale_fill_viridis() +
      labs(title = 'Total Pop for the fishnet') +
      mapTheme(),
nrow=1)
```

## osm data
```{r osm varialbe- not included}
# reference: https://wiki.openstreetmap.org/wiki/Map_features#Entertainment,_Arts_&_Culture
amenity_wm <- c('waste_basket','waste_disposal','waste_transfer_station','recycling') # done
water<- c('canal','drain','ditch') # done 
leisure <- c('park')
landuse <- c('commercial','residential','retail','industrial') # done 
highway <- c('motorway','trunk','primary','secondary','tertiary','unclassified','residential') # done
act <- c('maxspeed') 
amenity_food <- c('restaurant','pub','bar') # done
building <- ('apartments')

bb_df <- getbb(place_name = "mumbai india", format_out = "data.frame") # get  boundary
bdry <- bb_df$boundingbox # extract the geometry parts
bdry #output is a set of coordinates, follow the follow order for the 'boundary list' as indicated below
# 4, 2, 3, 1

chen_bd <- c(80.4301860, 13.2436939, 80.1101860, 12.8236939) # just a record


```

```{r get point_nn_fishnet}
water_point <- point_data(chen_bd, 'water',c('canal','drain','ditch'),'water') # grab osm point data (the detail input variable just check the 'https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/function_UO.R' and I have write the input require)
water_net <- countfishnet(fishnet,water_point) # create fn variable of litter count
water_nn_net <- knnfishnet(fishnet,water_point,3) # create fn knn variable 

waste_point <- point_data(chen_bd, 'amenity',c('waste_basket','waste_disposal','waste_transfer_station','recycling'),'waste')
waste_net <- countfishnet(fishnet,waste_point)
waste_nn_net <- knnfishnet(fishnet,waste_point,3)

rstrt_point <- point_data(chen_bd, 'amenity',c('restaurant','pub','bar'),'restaurant')
rstrt_net <- countfishnet(fishnet,rstrt_point)
rstrt_nn_net <- knnfishnet(fishnet,rstrt_point,3)

road_point <- point_data(chen_bd, 'highway','residential','road')
road_net <- countfishnet(fishnet,road_point)
road_nn_net <- knnfishnet(fishnet,road_point,3)

indstr_point <- point_data(chen_bd, 'landuse','industrial','industrial')
indstr_net <- countfishnet(fishnet,indstr_point)
indstr_nn_net <- knnfishnet(fishnet,indstr_point,3)

rsdnt_point <- point_data(chen_bd, 'landuse','residential','residential')
rsdnt_net <- countfishnet(fishnet,rsdnt_point)
rsdnt_nn_net <- knnfishnet(fishnet,rsdnt_point,3)

rtl_point <- point_data(chen_bd, 'landuse','retail','retail')
rtl_net <- countfishnet(fishnet,rtl_point)
rtl_nn_net <- knnfishnet(fishnet,rtl_point,3)
```

```{r chi-sq test}
print(chisq.test(water_net$count,litter_net$count)) # chi-square test 
print(chisq.test(rstrt_net$count,litter_net$count))
print(chisq.test(road_net$count,litter_net$count))
print(chisq.test(waste_net$count,litter_net$count)) 

print(chisq.test(indstr_net$count,litter_net$count))
print(chisq.test(rsdnt_net$count,litter_net$count))
print(chisq.test(rtl_net$count,litter_net$count))
```

```{r visualize count net}
visual_count_net(water_net,water_point,chen_bdry,'water') # visualize the point and fn count data
visual_count_net(waste_net,waste_point,chen_bdry,'waste')
visual_count_net(rstrt_net,rstrt_point,chen_bdry,'restaurant')
visual_count_net(road_net,road_point,chen_bdry,'road')
visual_count_net(indstr_net,indstr_point,chen_bdry,'Industrial Land Use')
visual_count_net(rsdnt_net,rsdnt_point,chen_bdry,'Residential Land Use')
visual_count_net(rtl_net,rtl_point,chen_bdry,'retail Land Use')

nn_visual(water_nn_net,'water') # visualize the knn variable data
nn_visual(waste_nn_net,'waste')
nn_visual(rstrt_nn_net,'restaurant')
nn_visual(road_nn_net,'road')
nn_visual(rtl_nn_net,'retail Land Use')
nn_visual(indstr_nn_net,'Residential Land Use')
nn_visual(indstr_nn_net,'Industrial Land Use')
```

```{r combine the final dataset}
# join all variable to a total dataset
## ATTENTION: just check the column name frequently, it shoulb be some column with same name needed to be rename
## current don't have zoning, remember to add it
final_net <-
  left_join(litter_net, st_drop_geometry(water_nn_net), by="uniqueID")

final_net <-
  left_join(final_net, st_drop_geometry(rstrt_nn_net), by="uniqueID")

final_net <-
  left_join(final_net, st_drop_geometry(road_nn_net), by="uniqueID")

final_net <- final_net%>%
  rename(watr_nn = item.nn.x,
         restaurant_nn = item.nn.y,
         road_nn = item.nn)

final_net <- 
  left_join(final_net,st_drop_geometry(avg_pop), by="uniqueID")

final_net <- 
  left_join(final_net,st_drop_geometry(sum_pop), by="uniqueID")

final_net <- 
  left_join(final_net,st_drop_geometry(indstr_nn_net), by="uniqueID")

final_net <- 
  left_join(final_net,st_drop_geometry(rsdnt_nn_net), by="uniqueID")

final_net <- 
  left_join(final_net,st_drop_geometry(rtl_nn_net), by="uniqueID")

final_net <- final_net%>%
  rename(indstr_nn = item.nn.x,
         rsdnt_nn = item.nn.y,
         rtl_nn = item.nn)
```

```{r local moran's I analysis}
final_net.nb <- poly2nb(as_Spatial(final_net), queen=TRUE) 

final_net.weights <- nb2listw(final_net.nb, style="W", zero.policy=TRUE) # get local moran spatial weight

# get the locan moral analysis of POI data
local_morans_rst <- localmoran(final_net$restaurant, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
local_morans_road <- localmoran(final_net$road, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
local_morans_wtr <- localmoran(final_net$water, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
local_morans_sp <- localmoran(final_net$sum_pop, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
local_morans_ap <- localmoran(final_net$avg_pop, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()

local_morans_indstr <- localmoran(final_net$industrial, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
local_morans_rsdnt <- localmoran(final_net$residential, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
local_morans_rtl <- localmoran(final_net$retail, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
```

```{r local moran analysis}
# attention!
# the legends here shoud be the same as label set when create the count fishnet
# visualize the local moran result
lc_mr_visual(local_morans_wtr,final_net,'water')
lc_mr_visual(local_morans_rst,final_net,'restaurant')
lc_mr_visual(local_morans_road,final_net,'road')
lc_mr_visual(local_morans_sp,final_net,'sum_pop')
lc_mr_visual(local_morans_ap,final_net,'avg_pop')

lc_mr_visual(local_morans_indstr,final_net,'industrial')
lc_mr_visual(local_morans_rsdnt,final_net,'residential')
lc_mr_visual(local_morans_rtl,final_net,'retail')
```

```{r add lm sig to dataset}
final_net <- lm_col(final_net,local_morans_wtr) # combine the local moran analysis significant point knn into final dataset
final_net <- final_net%>% rename(wtr_sig = col_name, wtr_sig_dis = col_name_dis) # rename the name of column

final_net <- lm_col(final_net,local_morans_road)
final_net <- final_net%>% rename(road_sig = col_name, road_sig_dis = col_name_dis)

final_net <- lm_col(final_net,local_morans_rst)
final_net <- final_net%>% rename(rst_sig = col_name, rst_sig_dis = col_name_dis)

final_net <- lm_col(final_net,local_morans_indstr)
final_net <- final_net%>% rename(indstr_sig = col_name, indstr_sig_dis = col_name_dis)

final_net <- lm_col(final_net,local_morans_rsdnt)
final_net <- final_net%>% rename(rsdnt_sig = col_name, rsdnt_sig_dis = col_name_dis)

final_net <- lm_col(final_net,local_morans_rtl)
final_net <- final_net%>% rename(rtl_sig = col_name, rtl_sig_dis = col_name_dis)
```

```{r significant variable viz}
# visualzie the signifcant point knn of variable
grid.arrange(
ggplot() +
      geom_sf(data = final_net, aes(fill=rst_sig_dis), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Restaurant NN Distance") +
      mapTheme(),
ggplot() +
      geom_sf(data = final_net, aes(fill=road_sig_dis), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Road NN Distance") +
      mapTheme(),
ggplot() +
      geom_sf(data = final_net, aes(fill=wtr_sig_dis), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Water NN Distance") +
      mapTheme(),
nrow = 1)
```

```{r normal rg model}
reg.ss.vars <- c("restaurant_nn", "rst_sig_dis","road_nn", "road_sig_dis","watr_nn", "wtr_sig_dis",'sum_pop') # the independent variables included

## RUN REGRESSIONS
reg.ss.spatialCV <- crossValidate(
  dataset = final_net,
  id = "uniqueID",                           
  dependentVariable = "count", # this count is the litter count 
  indVariables = reg.ss.vars) %>%
    dplyr::select(uniqueID, count, Prediction, geometry)
```

```{r viz error}
error_visual(reg.ss.spatialCV) # visualize the MSE of prediction
```

```{r risk map viz}
risk_visualize(reg.ss.spatialCV,litter_p) # visualize the risk map
```

```{r different models}
df_model <- st_drop_geometry(final_net)%>%dplyr::select(!cvID)

temp.rf <- randomForest(count ~ ., data = df_model%>%dplyr::select(!uniqueID), mtry = 10,ntree=70, 
                         importance = TRUE, na.action = na.omit) 

temp.lr <- glm(count ~ ., data = df_model%>%dplyr::select(!uniqueID),family = "poisson", na.action = na.omit) 

temp.lr.qs <- glm(count ~ ., data = df_model%>%dplyr::select(!uniqueID),family = "quasi", na.action = na.omit) 

temp.lr.qp <- glm(count ~ ., data = df_model%>%dplyr::select(!uniqueID),family = "quasipoisson", na.action = na.omit) 

nn_model = neuralnet(count ~ .,data=df_model%>%dplyr::select(!uniqueID),hidden=c(5,2),
linear.output = TRUE
)

fit.1<- brm(count~ ., data=df_model%>%dplyr::select(!uniqueID), family=gaussian(),
              warmup=500, #burnin for 500 interations for each chain = 1000 burnin
              iter=1000, chains=2, #2*1000 =2000 - 1000 burnin = 1000 total iterations
              cores=2,seed = 1115) #number of computer cores, 1 per chain is good.

# decision tree model
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
train_data <- training(data_split)
test_data <- testing(data_split)

# Create a decision tree model specification
tree_spec <- decision_tree(mode = "regression", tree_depth = 6,engine = 'rpart') 

# Fit the model to the training data
tree_fit <- tree_spec %>%
 fit(count ~ ., data = train_data)
```

```{r model predicted with only having values}
# the model only use fishnet having data
temp_net <- final_net %>%
  filter(count != 0)

temp_model <- st_drop_geometry(temp_net)%>%dplyr::select(!cvID)

temp.rf_s <- randomForest(count ~ ., data = temp_model%>%dplyr::select(!uniqueID), mtry = 10,ntree=70, 
                         importance = TRUE, na.action = na.omit) 

temp.lr_s <- glm(count ~ ., data = temp_model%>%dplyr::select(!uniqueID),family = "poisson", na.action = na.omit) 

temp.lr.qs_s <- glm(count ~ ., data = temp_model%>%dplyr::select(!uniqueID),family = "quasi", na.action = na.omit) 

temp.lr.qp_s <- glm(count ~ ., data = temp_model%>%dplyr::select(!uniqueID),family = "quasipoisson", na.action = na.omit) 

nn_model_s = neuralnet(count ~ .,data=temp_model%>%dplyr::select(!uniqueID),hidden=c(5,2),
linear.output = TRUE
)
```

```{r decision tree model}


```

```{r}
df_rf_rst <- model_process(df_model,temp.rf)
df_lr_rst <- model_process(df_model,temp.lr)
df_lrqs_rst <- model_process(df_model,temp.lr.qs)
df_lrqp_rst <- model_process(df_model,temp.lr.qp)
df_nn_rst <- model_process(df_model,nn_model)

df_rf_r <- model_result(df_model,temp.rf) %>%mutate(model = 'RF')
df_lr_r <- model_result(df_model,temp.lr) %>%mutate(model = 'LR')
df_lrqs_r <- model_result(df_model,temp.lr.qs)%>%mutate(model = 'LR_quasi')
df_lrqp_r <- model_result(df_model,temp.lr.qp)%>%mutate(model = 'LR_quasipoisson')
df_nn_r <- model_result(df_model,nn_model)%>%mutate(model = 'Neural Net')
df_r_tt <- do.call("rbind", list(df_rf_r, df_lr_r, df_lrqs_r,df_lrqp_r,df_nn_r))

df_rf_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_rf_rst, by="uniqueID")
df_lr_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_lr_rst, by="uniqueID")
df_lrqs_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_lrqs_rst, by="uniqueID")
df_lrqp_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_lrqp_rst, by="uniqueID")

df_brm_rst <- model_process(df_model,fit.1)
df_brm_r <- model_result(df_model,fit.1) %>%mutate(model = 'BRM')
df_brm_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_brm_rst, by="uniqueID")

#HrB regression part
estimates_list <- list()
# Iterate over each row by index
for(i in 1:nrow(df_brm_rst)) {
  # Extract the 'Prediction' for the current row
  current_prediction <- df_brm_rst$Prediction[[i]][1]
  estimates_list[[i]] <- current_prediction
}

df_brm_rst$Estimate <- estimates_list
df_brm_rst <- df_brm_rst %>%
  dplyr::select(uniqueID,count,geometry,Estimate)%>%
  rename(Prediction = Estimate)

df_brm_rst$Prediction <- as.numeric(unlist(df_brm_rst$Prediction))

# decision tree model prediction
predictions <- tree_fit %>%
 predict(df_model)%>%
 pull(.pred)

df_dt_rst <- df_model%>%
  mutate(Prediction = predictions)%>%
  dplyr::select(uniqueID,count,Prediction)

df_dt_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_dt_rst, by="uniqueID")
```

```{r trial model result}
# use the model only use fishnet having data to predict the whole area
df_rf_rst_s <- model_process(df_model,temp.rf_s)
df_lr_rst_s <- model_process(df_model,temp.lr_s)
df_lrqs_rst_s <- model_process(df_model,temp.lr.qs_s)
df_lrqp_rst_s <- model_process(df_model,temp.lr.qp_s)
df_nn_rst_s <- model_process(df_model,nn_model_s)

df_rf_r_s <- model_result(df_model,temp.rf_s) %>%mutate(model = 'RF')
df_lr_r_s <- model_result(df_model,temp.lr_s) %>%mutate(model = 'LR')
df_lrqs_r_s <- model_result(df_model,temp.lr.qs_s)%>%mutate(model = 'LR_quasi')
df_lrqp_r_s <- model_result(df_model,temp.lr.qp_s)%>%mutate(model = 'LR_quasipoisson')
df_nn_r_s <- model_result(df_model,nn_model_s)%>%mutate(model = 'Neural Net')
df_r_tt_s <- do.call("rbind", list(df_rf_r_s, df_lr_r_s, df_lrqs_r_s,df_lrqp_r_s,df_nn_r_s))

df_rf_rst_s <- left_join(final_net%>%dplyr::select(uniqueID),df_rf_rst_s, by="uniqueID")
df_lr_rst_s <- left_join(final_net%>%dplyr::select(uniqueID),df_lr_rst_s, by="uniqueID")
df_lrqs_rst_s <- left_join(final_net%>%dplyr::select(uniqueID),df_lrqs_rst_s, by="uniqueID")
df_lrqp_rst_s <- left_join(final_net%>%dplyr::select(uniqueID),df_lrqp_rst_s, by="uniqueID")
```

```{r model result}
# approach is from "fixed", "sd", "equal", "pretty", "quantile", "kmeans", "hclust", "bclust", "fisher", "jenks", "dpih", "headtails", "maximum", or "box"
dvd_mth <- c("sd", "equal", "pretty", "quantile", "kmeans", "hclust", "bclust", "fisher", "jenks", "dpih", "headtails", "maximum", "box")

risk_v(df_rf_rst,litter_p,"headtails")
risk_v(df_lr_rst,litter_p,"headtails")
risk_v(df_lrqs_rst,litter_p,"headtails")
risk_v(df_lrqp_rst,litter_p,"headtails")
risk_v(df_brm_rst,litter_p,"headtails")
risk_v(reg.ss.spatialCV,litter_p,"headtails")
risk_v(df_brm_rst,litter_p,"kmeans")
risk_v(df_dt_rst,litter_p,"kmeans")
```


# Why not function?
the approach is totally not make sense (the way ignore the cluster of litter, but will just highlight the place with similar varialbe situation)
```{r model with having value risk viz}
# approach is from "fixed", "sd", "equal", "pretty", "quantile", "kmeans", "hclust", "bclust", "fisher", "jenks", "dpih", "headtails", "maximum", or "box"
risk_v(df_rf_rst_s,litter_p,"kmeans")
risk_v(df_lr_rst_s,litter_p,"kmeans")
risk_v(df_lrqs_rst_s,litter_p,"kmeans")
risk_v(df_lrqp_rst_s,litter_p,"kmeans")
```


2. about EDA:
new model applied: hierarchical bayes regression & decision tree
why this two model:
hierarchical bayes regression：'experimental data in cognitive science contain “clusters”. These are natural groups that contain observations that are more similar within the clusters than between them.'  perhaps the feature could somehow decrease the influence from 

Hierarchical modeling is used when information is available on several different levels of observational units. this feature may help when we model multiple cities（in epidemiological modeling to describe infection trajectories for multiple countries, ）

```{r final chosen model current}
# dvd_mth <- c("sd", "equal", "pretty", "quantile", "kmeans", "hclust", "bclust", "fisher", "jenks", "dpih", "headtails", "maximum", "box")
#partytime(df_brm_rst)

grid.arrange(
risk_v(df_brm_rst,litter_p,"headtails"),
ggplot() + 
      geom_sf(data = chen_bdry) +
      geom_sf(data = water_point, colour="red", size=0.2, show.legend = "point") +
      labs(title= paste('water',", Chennai")) +
      mapTheme(title_size = 14),nrow=1
)
```


