---
title: "Ocean Conservancy, Urban Oceans Marine Debris Prediction"
subtitle: "Trevor Kapuvari, Shreya Bansal, Tianxiao Chen, Stephanie Cheng, Xiaofan Liu"
author: "Unviersity of Pennsylvania"
date: "2024-01-30"
output:
  html_document:
    toc: yes
    theme: cosmo
    toc_float: yes
    code_folding: hide
    number_sections: yes
---

# Introduction

The Ocean Conservancy's Urban Ocean program has been developing projects that mitigate marine pollution, assess waste management, and enable cities to address ocean plastics and resilience. These projects intend to deploy "zero-waste" pilot solutions in multiple cities where they have partnerships and collected information regarding their waste management circumstances. Our objective is to develop a litter-accumulation assessment model that identifies effective zero-waste site locations for national and multinational use. This geosaptial risk assessment model serves the purpose of predicting litter accumulation based on globally sourced data with a repeatable framework on an international scale. The results of the model evaluate which sections of a given area have the highest likelihood to produce and contain litter relative to its surroundings. For our case, the Urban Ocean program intends to dedicate "zero-waste" solutions in these areas for the most effective impact for each deployment.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(classInt)
library(RCurl)
library(httr)
library(osmdata)
library(randomForest)

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
st_c    <- st_coordinates
st_coid <- st_centroid

palette6 <- c("#264653","#2a9d8f",'#8AB17D',"#e9c46a",'#f4a261',"#e76f51")
palette5 <- c("#264653","#2a9d8f","#e9c46a",'#f4a261',"#e76f51")
palette4 <- c("#264653","#2a9d8f","#e9c46a","#e76f51")
palette2 <- c("#264653","#2a9d8f")
```

```{r function build, results='hide'}
countfishnet <- function(fishnet,dataset){
  net <- 
  dplyr::select(dataset) %>% 
  mutate(count = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(count = replace_na(count, 0),
         uniqueID = 1:n(),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))
  return(net)
}

knnfishnet <- function(fishnet,dataset,knum){
  vars_net <- dataset%>%
    st_join(fishnet, join=st_within) %>%
    st_drop_geometry() %>%
    group_by(uniqueID,osm_id) %>%
    summarize(count = n()) %>%
    left_join(fishnet, ., by = "uniqueID") %>%
    spread(osm_id, count, fill=0) %>%
    dplyr::select(-`<NA>`) %>%
    ungroup()
  vars_net <- vars_net %>%
    mutate(item.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(dataset),
                                           k = knum))
  return(vars_net)
}

visual <- function(net_one,point_one,variable_name){
grid.arrange(
  ggplot() +
  geom_sf(data = net_one, aes(fill = count), color = NA) +
  scale_fill_viridis() +
  labs(title = paste(variable_name,"count for the fishnet")) +
  mapTheme(),
  ggplot() + 
  geom_sf(data = chen_bdry) +
  geom_sf(data = point_one, colour="red", size=0.2, show.legend = "point") +
  labs(title= paste(variable_name,", Chennai")) +
  mapTheme(title_size = 14),
  nrow = 1
)
}
```

```{r, message=FALSE, warning=FALSE, results='hide'}
litter <- read.csv('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/mdt-dataChennai.csv')

litter_p <- litter%>%
  filter(master_material == 'PLASTIC')%>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")%>%
  st_transform('EPSG:32643')

chen_bdry <- st_read('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/gcc-divisions-latest.kml')
chen_bdry <- st_set_crs(chen_bdry, 4326)%>%
  st_transform('EPSG:32643')

fishnet <- 
  st_make_grid(chen_bdry,
               cellsize = 500, 
               square = TRUE) %>%
  .[chen_bdry] %>%            
  st_sf() %>%
  mutate(uniqueID = 1:n())
```

```{r, message=FALSE, warning=FALSE, results='hide'}
litter_people <- litter_p%>%
  group_by(username)%>%
  tally()
```

# Initial Analysis and Preperation

For our first model, we directed our focus on Chennai, India. The data regarding the region and its attributes was sourced solely by global open-source resources such as OpenStreetMaps (OSM) to ensure a repeatable framework & quality consistency. For each selected city we developed a 'boundary box' automated by OSM simply by specifying the name of the area (city & nation) and using the output coordinates as the scope of data acquisition. From there, further attributes of the area with respect to structures, networks, or political divisions can be extracted for use.

In terms of our dependent variable, litter data, the process required manually downloading data from Marine Debris Tracker (<https://www.debristracker.org/data/>). Each selected city required its own evaluation in terms of quantitative debris data over a several year time span. Ideal locations featured several thousand data points across 2-3 years for early-stage model development. Despite the scalability of the model itself, results and accuracy lay contingent on data quantity and external factors.

```{r, warning=FALSE, message=FALSE}
grid.arrange(
  ggplot() + 
  geom_sf(data = chen_bdry) +
  geom_sf(data = litter_p, colour="red", size=0.2, show.legend = "point") +
 # geom_sf(data = litter_p%>%filter(username == 'Chandranram'), colour="green", size=0.2, show.legend = "point") +
  mapTheme(title_size = 14),
  nrow = 1
)
```


The litter data featured a wide variety of item categories and general information about each piece. Despite the quality of detail for each recorded sample, this only accounts for litter that has been identified, recorded, and disposed of. This data does not account for litter that was identified but never disposed of, accounted for, or assumed. Regardless, areas where litter was not recorded in a general surrounding could not confidently be assumed to be present or not present.

## Marine Debris Data, in Summary

Each graph below describes the observed litter data acquired from the Marine Debris Tracker (MDT). The most important feature we looked at in predicting accumulation or the possibility of additional unrecorded samples were quantity, altitude, and radius.

Quantity measured groupings of specific litter samples that were disposed of at the same time & place.

Altitude measured the elevation of recorded litter, ranging widely between steep terrain throughout Chennai or holes/ditches far below sea level.

Radius functioned as a confidence interval for coordinates and known accuracy of where the litter was recorded, majority of which had consistent readings with notably some outliers.

The bar graph of 'Main Item Category' measures each type of litter found in the dataset, the project goals focused heavily on plastic and plastic-related waste. As a result, the largest counts of items measured are plastic-based products.

```{r message=FALSE, warning=FALSE}
grid.arrange(
  ggplot(litter_p, aes(x = quantity)) + 
  geom_bar() +
  theme_minimal() +
  labs(title = "Count of Quantity Per Record",
       x = "Category",
       y = "Count"),
  ggplot(litter_p, aes(x = altitude)) + 
  geom_histogram() +
  theme_minimal() +
  labs(title = "Altitude Histogram",
       x = "Category",
       y = "Count"),
  ggplot(litter_p, aes(x = radius)) + 
  geom_histogram() +
  theme_minimal() +
  labs(title = "Radius Histogram",
       x = "Category",
       y = "Count"),
  ncol = 3
)

ggplot(litter_p, aes(x = master_item_name)) + 
  geom_bar() +
  theme_minimal() +
  labs(title = "Count of Main Item Category",
       x = "Category",
       y = "Count")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(litter_p, aes(x = location)) + 
  geom_bar() +
  theme_minimal() +
  labs(title = "Count of Location in Litter Record",
       x = "Category",
       y = "Count")+
  theme(axis.text.x = element_text(angle = 25,size = 6))
```

## Chennai Debris Analysis

With the boundary of the city and litter within acquired and accounted for, we could evaluate Chennai's litter data situation through a fishnet grid. The fishnet grid allows us to categorize the city into uniformed sections, identify concentrations of data, and allow our model to quantify predictions in terms of quantity by cell rather than by precise locations.

```{r,  message=FALSE, warning=FALSE}
litter_net <- 
  dplyr::select(litter_p) %>% 
  mutate(countlitter = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countlitter = replace_na(countlitter, 0),
         uniqueID = 1:n(),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

ggplot() +
  geom_sf(data = litter_net, aes(fill = countlitter), color = NA) +
  scale_fill_viridis() +
  labs(title = "Count of Litter for the fishnet") +
  mapTheme()
```

# Data Gathering and Variables

The primary importance of our independent variables is to function as indicators for human activity and, indirectly, litter distribution. The aim of these variables is to act as substitutes for litter, providing insight on where litter most likely accumulated or ends up. These variables, similarly to litter, are analyzed on a fishnet grid where the quantity is counted per cell. Each variable is then placed on a combined fishnet grid with the litter data, computed using a Chi-Squared test, and evaluated for association between the variables and litter.

## OpenStreetMap Variable Acquisition 

Our variables acquired to compare correlations include, waste management facilities, bodies of water, parks, land use, roadways, food-service amenities, and apartments. Below features the code example for OSM variable & city boundary defining & gathering. 

```{r, message=FALSE, warning=FALSE, results='hide'}
# reference: https://wiki.openstreetmap.org/wiki/Map_features#Entertainment,_Arts_&_Culture
amenity_wm <- c('waste_basket','waste_disposal','waste_transfer_station','recycling')
water<- c('canal','drain','ditch')
leisure <- c('park')
landuse <- c('commercial','residential','retail')
highway <- c('motorway','trunk','primary','secondary','tertiary','unclassified','residential')
act <- c('maxspeed')
amenity_food <- c('restaurant','pub','bar')

building <- ('apartments,')
```

```{r, message=FALSE, warning=FALSE, results='hide'}
india <- getbb(place_name = "india", format_out = "polygon")
bb_df <- getbb(place_name = "chennai india", format_out = "data.frame")
bdry <- bb_df$boundingbox
chen_bd <- c(80.4301860, 13.2436939, 80.1101860, 12.8236939)
```

```{r, message=FALSE, warning=FALSE, results='hide'}
bb_mb <- getbb(place_name = "mumbai india", format_out = "data.frame")
```

```{r transportation, message=FALSE, warning=FALSE, results='hide'}
trans <- opq(bbox = chen_bd) %>%
    add_osm_feature(key = 'highway', value = 'residential')%>%
  osmdata_sf()

trans_point <- bind_rows(
  pluck(trans,'osm_points'),
  st_centroid(pluck(trans,'osm_lines'))
)%>%dplyr::select(osm_id,geometry)%>%
  st_transform('EPSG:32643')%>%
  mutate(legend = 'road')

road_net <- countfishnet(fishnet,trans_point)
vars_net <- knnfishnet(fishnet,trans_point,3)
```

## Independent Variables Examined

### Residential Roads, Fishnet & Raw Data

To keep all data acquired to be interpreted uniformly, we add our independent variables on a fishnet grid as shown below. Notably, using the raw value/geometry of each set does not assist with visual display or comprehension of data. 

```{r trans visualization}
visual(road_net,trans_point,'residential road')
```

```{r, warning=FALSE, message=FALSE}
litter_no <- st_drop_geometry(litter_net)%>%dplyr::select(countlitter, uniqueID)
corr_trans_net <- road_net %>%
  left_join(litter_no, by = "uniqueID")
print(chisq.test(corr_trans_net$count,corr_trans_net$countlitter))
```

### Restaurants, Fishnet & Raw Data

```{r restaurant data, cache=TRUE}
restrt <- opq(bbox = chen_bd) %>%
    add_osm_feature(key = 'amenity', value = c('restaurant','pub','bar'))%>%
  osmdata_sf()

restrt_point <- pluck(restrt,'osm_points')%>%
  dplyr::select(osm_id,geometry)%>%
  st_transform('EPSG:32643')%>%
  mutate(legend = 'restaurant')

rstrt_net <- countfishnet(fishnet,restrt_point)
visual(rstrt_net,restrt_point,'restaurant')
```

```{r corr-rest-litter, warning=FALSE}
corr_net <- rstrt_net %>%
  left_join(litter_no, by = "uniqueID")
print(chisq.test(corr_net$count,corr_net$countlitter))
```

#### Nearest Neighbor Fishnet, Restaurants

For specific variables such as restaurants, we wanted to examine a nearest neighbor analysis because of their direct implication with high human activity, excess flow of goods, and interconnection of urban systems. Areas of low distances of a "nearest neighbor" imply restaurants are close to one another geographically, indicate density in resources, and identify an urban core. 

```{r, warning=FALSE, message=FALSE, results='hide'}
vars_net_rstrt <- knnfishnet(fishnet,restrt_point,3)

vars_net_rstrt.long.nn <- 
  dplyr::select(vars_net_rstrt, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

ggplot() +
      geom_sf(data = vars_net_rstrt.long.nn, aes(fill=value), colour=NA) +
      scale_fill_viridis(name="Distance") +
      labs(title="Restaurant Nearest Neighbor Distance") +
      mapTheme()
```

### In-land Water Distribution

Water was an additional indicator to be further examined due to the physical circumstances surrounding marine debris. Often times, when litter/waste ends up in water, the waste will not  naturally exit the body of water and reside on nearby shore or be carried to other bodies. These areas are also a heavier focus by Urban Oceans as marine pollution is a key focus. 

```{r water data}
chen_water <- opq(bbox = chen_bd) %>%
    add_osm_feature(key = 'water', value = water)%>%
  osmdata_sf()

chen_water_point <- pluck(chen_water,'osm_points')%>%
  dplyr::select(osm_id,geometry)%>%
  st_transform('EPSG:32643')%>%
  mutate(legend = 'water')

water_net <- countfishnet(fishnet,chen_water_point)
visual(water_net,chen_water_point,'water')
```

```{r water visualization, warning=FALSE}
corr_water_net <- water_net %>%
  left_join(litter_no, by = "uniqueID")
print(chisq.test(corr_water_net$count,corr_water_net$countlitter))
```

#### Nearest Neighbor, In-land Water Distribution

On this fishnet grid we notice sections adjacent to the coastline (east) create two centers with low 'nearest neighbor' values, also places that loosely defined outlined sections similar to restaurants.  

```{r, warning=FALSE, message=FALSE}
vars_net_water <- knnfishnet(fishnet,chen_water_point,3)

vars_net_water.long.nn <- 
  dplyr::select(vars_net_water, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

ggplot() +
      geom_sf(data = vars_net_water.long.nn, aes(fill=value), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Water Nearest Neighbor Distance") +
      mapTheme()
```

### Waste Manageament

Here we can make two assumptions regarding the influence of waste management and its effects on litter distribution: 

a) The waste management facilities reduces the surrounding litter.

b) The facilities are distant from places of high human activity, not necessarily implying that its location reduces its surrounding litter. 

```{r waste data}
chen_waste <- opq(bbox = chen_bd) %>%
    add_osm_feature(key = 'amenity', value = amenity_wm)%>%
  osmdata_sf()

chen_waste_point <- pluck(chen_waste,'osm_points')%>%
  dplyr::select(osm_id,geometry)%>%
  st_transform('EPSG:32643')

waste_net <- countfishnet(fishnet,chen_waste_point)
visual(waste_net,chen_waste_point,'waste management')
```

```{r waste visualization, warning=FALSE}
corr_waste_net <- waste_net %>%
  left_join(litter_no, by = "uniqueID")
print(chisq.test(corr_waste_net$count,corr_waste_net$countlitter))
```

#### Fishnet, Waste Manageament

We notice most waste management facilities are central and south in the city, showing mild correlations between previous variables and the urban core & coastline where we wish to prevent litter accumulation from occurring. 

```{r, warning=FALSE, message=FALSE}
vars_net_waste <- knnfishnet(fishnet,chen_waste_point,3)

vars_net_waste1.long.nn <- 
  dplyr::select(vars_net_waste, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

ggplot() +
      geom_sf(data = vars_net_waste1.long.nn, aes(fill=value), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Waste 3NN Distance") +
      mapTheme()
```

```{r, warning=FALSE, message=FALSE, results='hide'}
vars_net_rstrt <- knnfishnet(fishnet,restrt_point,3)
final_net <-
  left_join(litter_net, st_drop_geometry(vars_net_rstrt), by="uniqueID") 
```

```{r}
final_net.nb <- poly2nb(as_Spatial(final_net), queen=TRUE)
final_net.weights <- nb2listw(final_net.nb, style="W", zero.policy=TRUE)
```

# Spatial Analysis

We look at several statistical measurements to improve our understanding of how these independent variables correlation and associate with the litter data. 

Litter_Count: Shows the raw measurement of litter found throughout the city

Local Moran's I: Measures spatial autocorrelation among litter within the city, there is mostly no autocorrelation with a potential exception in the northern tip. 

P Value: Records statistical significance, there  is a peculiar pattern made for areas that are not  considered significant which may question is potential insight to be gained from this particular evaluation. 

Significant Hotspot: Detects potential hotspots for litter, which appears to not directly relate where litter counts are found to be. 

```{r, warning=FALSE, message=FALSE, results='hide'}
## see ?localmoran
local_morans <- localmoran(final_net$item.nn, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()

# join local Moran's I results to fishnet
final_net.localMorans <- 
  cbind(local_morans, as.data.frame(final_net)) %>% 
  st_sf() %>%
  dplyr::select(Litter_Count = countlitter, 
                Local_Morans_I = Ii, 
                P_Value = `Pr(z != E(Ii))`) %>%
  mutate(Significant_Hotspots = ifelse(P_Value <= 0.001, 1, 0)) %>%
  gather(Variable, Value, -geometry)
```

```{r}
vars <- unique(final_net.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme(title_size = 14) + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Morans I statistics, Chennai"))
```

```{r, warning=FALSE, message=FALSE, results='hide', cache=TRUE}
final_net <- final_net %>% 
  mutate(restaurant.isSig = 
           ifelse(local_morans[,5] <= 0.001, 1, 0)) %>%
  mutate(restaurant.isSig.dist = 
           nn_function(st_c(st_coid(final_net)),
                       st_c(st_coid(filter(final_net, 
                                           restaurant.isSig == 1))), 
                       k = 1))
```


## Restuarant Signfiance 

Restaurants are used as a point of significance because of their indirectly relation to commercial activity. We notice here there is more 'NN Distance' in the south due to the lack of restaurants and general activity.  

```{r}
ggplot() +
      geom_sf(data = final_net, aes(fill=restaurant.isSig.dist), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Restaurant Signficance Distance") +
      mapTheme()
```

```{r}
weight_net <- 
  left_join(litter_net, st_drop_geometry(road_net), by="uniqueID") 
weight_net <- weight_net %>% rename(countroad = count) %>% dplyr::select(!starts_with('cv'))

weight_net <- 
  left_join(weight_net, st_drop_geometry(water_net), by="uniqueID") 
weight_net <- weight_net %>% rename(countwater = count) %>% dplyr::select(!starts_with('cv'))

weight_net <- 
  left_join(weight_net, st_drop_geometry(rstrt_net), by="uniqueID") 
weight_net <- weight_net %>% rename(countrstrt = count) %>% dplyr::select(!starts_with('cv'))
```

## Concluded Results
 !!! BENCH MARK!!!
 
 Trevor: redo paragraphs below
 Stephanie: 1 hard read for spell check, logic flow, grammar, etc. Optimize all R chunks with cache=true.
 
 
With all considered in terms of all statistical tests and independent variables measured, water and restaurants act as the greatest associated indicators for litter accumulation. Regarding other aspects and measurements considered, such as Moran's I and and hotspots, there is sufficient data to, at minimum, evaluate model performance in assessing litter accumulation. It is noted that additional variables that build upon litter assessment will enhance the model's accuracy. This run-through acts as the initial development process in the machine-learning approach to Urban Ocean's objectives and needs.
 
Talk about inverse in p value hot spot in rest sig maps




# Modeling

In light of the inherent bias stemmed from litter data, we also are developing a 'Reduced Bias' Model in attempt to compensate for potential  assumptions made by the model in terms of quantity. We take each indicator and coalesce them into a single variable used for our model to compare litter data to the indicators. 

```{r function trial, warning=FALSE, message=FALSE, results='hide'}
knnfishnet_new <- function(fishnet,dataset,knum){
  vars_net <- dataset%>%
    st_join(fishnet, join=st_within) %>%
    st_drop_geometry() %>%
    group_by(uniqueID,legend) %>%
    summarize(count = n()) %>%
    left_join(fishnet, ., by = "uniqueID") %>%
    spread(legend, count, fill=0) %>%
    dplyr::select(-`<NA>`) %>%
    ungroup()
  vars_net <- vars_net %>%
    mutate(item.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(dataset),
                                           k = knum))
  return(vars_net)
}

rest_net_temp <- knnfishnet_new(fishnet,restrt_point,3)
tran_net_temp <- knnfishnet_new(fishnet,trans_point,3)
water_net_temp <- knnfishnet_new(fishnet,chen_water_point,3)
```


## Visualizing Variables and Analysis 
This model requires us to re-examine similar or duplicate variables and measuring their integrity for acting as indicators of litter. We are specifically looking at the nearest neighbor index to evaluate the clustering created by each variable or any correlated patterns paralleled by litter data. 


### Nearest Neighbor Series 

Here, we further examine the nearest neighbor distances of restaurants, roads, and water, all of which have identical patterns to previous analyses. Each has a somewhat similar outcome to nearest neighbor maps prior, and do not provide insight on litter accumulation alone.  

```{r}
rest_net_temp.long.nn <- 
  dplyr::select(rest_net_temp, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

tran_net_temp.long.nn <- 
  dplyr::select(tran_net_temp, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

water_net_temp.long.nn <- 
  dplyr::select(water_net_temp, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

grid.arrange(
ggplot() +
      geom_sf(data = rest_net_temp.long.nn, aes(fill=value), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Restaurant NN Distance")+
      mapTheme()+
      theme(plot.title = element_text(size = 10, hjust = 0)),
ggplot() +
      geom_sf(data = tran_net_temp.long.nn, aes(fill=value), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Road NN Distance") +
      mapTheme()+
      theme(plot.title = element_text(size = 10, hjust = 0)),
ggplot() +
      geom_sf(data = water_net_temp.long.nn, aes(fill=value), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Water NN Distance") +
      mapTheme()+
      theme(plot.title = element_text(size = 10, hjust = 0)),
nrow = 1)
```



```{r, warning=FALSE, message=FALSE, results='hide'}
final_net <-
  left_join(litter_net, st_drop_geometry(rest_net_temp), by="uniqueID")

final_net <-
  left_join(final_net, st_drop_geometry(tran_net_temp), by="uniqueID")

final_net <-
  left_join(final_net, st_drop_geometry(water_net_temp), by="uniqueID")%>%
  rename(rst_nn = item.nn.x,
         road_nn = item.nn.y,
         wtr_nn = item.nn)
```

```{r, warning=FALSE, message=FALSE, results='hide'}
final_net.nb <- poly2nb(as_Spatial(final_net), queen=TRUE)
## ... and neighborhoods to list of weigths
final_net.weights <- nb2listw(final_net.nb, style="W", zero.policy=TRUE)
```

```{r}
local_morans_rst <- localmoran(final_net$restaurant, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
local_morans_road <- localmoran(final_net$road, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
local_morans_wtr <- localmoran(final_net$water, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
```

### Statistic Analysis, Restaurants 

Restaurants function as the great association with litter currently presented in the model. In terms of the model theory, the restaurants themselves are not the direct cause of litter but are present in areas that have high traffic/density of people, proximity of commercial activity, and overall are in areas with large flows of goods and people, indirectly associating with litter accumulation. Restaurants function less as litter accumulation places but proxies to signify high human activity. 

When examining the Moran's I, measuring spatial autocorrelation, we notice there is little autocorrelation in majority of Chennai, this serves a positive indication that the model will not be bias towards a specific portion of the city and will evaluate all areas with respect to restaurants or other variables. 

The P Value and Significant Hotspot map examine the inverse relationship between significance and known clustering. P value shows where there is statistical significance of restaurants, showing specific cores in the central north, far west, and a downward strip on the south. Yet, the hotspot map shows those almost-same spots as hotspots for restaurants, proving a highlight of where restaurants cluster and the urban cores of the city. 
  


```{r, warning=FALSE, message=FALSE, results='hide'}
final_net.localMorans <- 
  cbind(local_morans_wtr, as.data.frame(final_net)) %>% 
  st_sf() %>%
  dplyr::select(rest_count = restaurant, 
                Local_Morans_I = Ii, 
                P_Value = `Pr(z != E(Ii))`) %>%
  mutate(Significant_Hotspots = ifelse(P_Value <= 0.001, 1, 0)) %>%
  gather(Variable, Value, -geometry)

vars <- unique(final_net.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme(title_size = 14) + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Morans I statistics, of literally what?"))
```

```{r, warning=FALSE, message=FALSE, results='hide'}
final_net <- final_net %>% 
  mutate(rstrt.isSig = 
           ifelse(local_morans_rst[,5] <= 0.001, 1, 0)) %>%
  mutate(rstrt.isSig.dist = 
           nn_function(st_c(st_coid(final_net)),
                       st_c(st_coid(filter(final_net, 
                                           rstrt.isSig == 1))), 
                       k = 1))

final_net <- final_net %>%
  mutate(road.isSig = 
           ifelse(local_morans_road[,5] <= 0.001, 1, 0)) %>%
  mutate(road.isSig.dist = 
           nn_function(st_c(st_coid(final_net)),
                       st_c(st_coid(filter(final_net, 
                                           road.isSig == 1))), 
                       k = 1))

final_net <- final_net %>%
  mutate(wtr.isSig = 
           ifelse(local_morans_wtr[,5] <= 0.001, 1, 0)) %>%
  mutate(wtr.isSig.dist = 
           nn_function(st_c(st_coid(final_net)),
                       st_c(st_coid(filter(final_net, 
                                           wtr.isSig == 1))), 
                       k = 1))
```

```{r eval=FALSE, include=FALSE}
grid.arrange(
ggplot() +
      geom_sf(data = final_net, aes(fill=rstrt.isSig.dist), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Restaurant NN Distance") +
      mapTheme(),
ggplot() +
      geom_sf(data = final_net, aes(fill=road.isSig.dist), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Road NN Distance") +
      mapTheme(),
ggplot() +
      geom_sf(data = final_net, aes(fill=wtr.isSig.dist), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Water NN Distance") +
      mapTheme(),
nrow = 1)
```

```{r message=FALSE, warning=FALSE, results='hide'}
reg.ss.vars <- c("rst_nn", "rstrt.isSig.dist","road_nn", "road.isSig.dist","wtr_nn", "wtr.isSig.dist")

## RUN REGRESSIONS
reg.ss.spatialCV <- crossValidate(
  dataset = final_net,
  id = "uniqueID",                           
  dependentVariable = "countlitter",
  indVariables = reg.ss.vars) %>%
    dplyr::select(uniqueID, countlitter, Prediction, geometry)
```

# Model Results 

After a full analysis on variables, model development, and statistical evaluation of all relations, we developed a risk assessment model. The results that follow examine the numeric, visual, and decision implications of the model's outcome. The goal of the results is to evaluate the general accuracy of the model in terms of Chennai alone, detect the potential accumulation risk zones, and adjust the framework for generalizability for other cities. 

## Mean Absolute Error of Model

We see negligible error for vast majority of litter. These results do not relate to the potential of other cities but act as a benchmark in the current stage of development. Majority of litter points are not considered to be subject to absolute error.

```{r, warning=FALSE, message=FALSE, results='hide'}
error_by_reg_and_fold <- 
  reg.ss.spatialCV %>%
    group_by(uniqueID) %>% 
    summarize(Mean_Error = mean(Prediction - countlitter, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold %>% 
  arrange(desc(MAE))

error_by_reg_and_fold %>% 
  arrange(MAE)

```


```{r, warning=FALSE, message=FALSE}
error_by_reg_and_fold %>% filter(MAE <=10) %>%
  ggplot(aes(MAE)) + 
    geom_histogram(bins = 60, colour="black", fill = "#FDE725FF") +
  scale_x_continuous(breaks = seq(0, 11, by = 1)) + 
    labs(title="Distribution of MAE", subtitle = "LOGO-CV",
         x="Mean Absolute Error", y="Count")
```

```{r}
ml_breaks <- classIntervals(reg.ss.spatialCV$Prediction, 
                             n = 5, "fisher")
litter_risk_sf <-
  reg.ss.spatialCV %>%
  mutate(label = "Risk Predictions",
         Risk_Category =classInt::findCols(ml_breaks),
         Risk_Category = case_when(
           Risk_Category == 5 ~ "5th",
           Risk_Category == 4 ~ "4th",
           Risk_Category == 3 ~ "3rd",
           Risk_Category == 2 ~ "2nd",
           Risk_Category == 1 ~ "1st")) %>%
  cbind(
    aggregate(
      dplyr::select(litter_p) %>% mutate(litterCount = 1), ., sum) %>%
      mutate(litterCount = replace_na(litterCount, 0))) %>%
  dplyr::select(label,Risk_Category, litterCount)
```

## Predictions & Results by Category 

The model produces a risk assessment that categorizes the city into 5 sections, 1 being the lowest risk for litter production while 5 is the highest. For what the model has predicted, there appears to be a core prediction in the central area and a smaller core in the south. There is reasonable concern regarding the fact no section where the model predicting category 4 or 5 are where litter was recorded. What needs to be considered is the pattern the model detects, the purpose of the model is not to depict where litter was already recorded, but where it was not. 

When looking at the current litter points (red dots), we see a vague circularly pattern for the larger core. The model appears to notice this pattern and is stating there is potential litter in the center of the "circle" where pre-recorded litter encircles yet feature zero data points. 

```{r}
ggplot() +
    geom_sf(data = litter_risk_sf, aes(fill = Risk_Category), colour = NA) +
    geom_sf(data = litter_p, size = .3, colour = "red") +
    scale_fill_viridis(discrete = TRUE) +
    labs(title="Litter Risk Predictions, Chennai",
         subtitle="") +
    mapTheme(title_size = 14)
```

## Compensating Bias Experiment 

Assuming litter found in one spot means litter found in its surrounding, we created random points in the surrounding area to act as additional to data quantity. 

```{r}
generate_populated_points <- function(litter_df) {
  populated_points_df <- data.frame(
    list_name = character(),
    master_item_name = character(),
    master_material = character(),
    itemname = character(),
    material = character(),
    quantity = numeric(),
    description = character(),
    latitude = numeric(),
    longitude = numeric(),
    altitude = numeric(),
    radius = numeric(),
    location = character(),
    timestamp = character(),
    dt = character(),
    project_name = character(),
    username = character(),
    manual_upload = character(),
    event_name = character(),
    id = character(),
    log_index = numeric(),
    legend = character()
  )
  
  for (i in 1:nrow(litter_df)) {
    center_lat <- litter_df$latitude[i]
    center_lon <- litter_df$longitude[i]
    
    # generate points from 1 to 20, change the num to change the range
    num_points <- sample(1:20, 1)
    
    for (j in 1:num_points) {
      new_lat <- center_lat + runif(1, -0.0045, 0.0045) 
      new_lon <- center_lon + runif(1, -0.0045, 0.0045)
      
      new_row <- litter_df[i, ]
      new_row$latitude <- new_lat
      new_row$longitude <- new_lon
      new_row$legend <- 'allrandom'
      
      populated_points_df <- rbind(populated_points_df, new_row)
    }
  }
  
  return(populated_points_df)
}

# test
allrandom_points_df <- generate_populated_points(litter)
```

```{r}
allrandom_points_df <- allrandom_points_df%>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")%>%
  st_transform('EPSG:32643')

litter_net_new <- 
  dplyr::select(allrandom_points_df) %>% 
  mutate(countlitter = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countlitter = replace_na(countlitter, 0),
         uniqueID = 1:n(),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

ggplot() +
  geom_sf(data = litter_net_new, aes(fill = countlitter), color = NA) +
  scale_fill_viridis() +
  labs(title = "Count of Litter for the fishnet") +
  mapTheme()
```

```{r, warning=FALSE, message=FALSE, results='hide'}
final_net_new <-
  left_join(litter_net_new, st_drop_geometry(rest_net_temp), by="uniqueID")

final_net_new <-
  left_join(final_net_new, st_drop_geometry(tran_net_temp), by="uniqueID")

final_net_new <-
  left_join(final_net_new, st_drop_geometry(water_net_temp), by="uniqueID")%>%
  rename(rst_nn = item.nn.x,
         road_nn = item.nn.y,
         wtr_nn = item.nn)
```

```{r, warning=FALSE, message=FALSE, results='hide'}
local_morans_rst_n <- localmoran(final_net_new$restaurant, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
local_morans_road_n <- localmoran(final_net_new$road, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
local_morans_wtr_n <- localmoran(final_net_new$water, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()
```

```{r, warning=FALSE, message=FALSE, results='hide'}
final_net_new <- final_net_new %>% 
  mutate(rstrt.isSig = 
           ifelse(local_morans_rst_n[,5] <= 0.001, 1, 0)) %>%
  mutate(rstrt.isSig.dist = 
           nn_function(st_c(st_coid(final_net_new)),
                       st_c(st_coid(filter(final_net_new, 
                                           rstrt.isSig == 1))), 
                       k = 1))

final_net_new <- final_net_new %>%
  mutate(road.isSig = 
           ifelse(local_morans_road_n[,5] <= 0.001, 1, 0)) %>%
  mutate(road.isSig.dist = 
           nn_function(st_c(st_coid(final_net_new)),
                       st_c(st_coid(filter(final_net_new, 
                                           road.isSig == 1))), 
                       k = 1))

final_net_new <- final_net_new %>%
  mutate(wtr.isSig = 
           ifelse(local_morans_wtr_n[,5] <= 0.001, 1, 0)) %>%
  mutate(wtr.isSig.dist = 
           nn_function(st_c(st_coid(final_net_new)),
                       st_c(st_coid(filter(final_net_new, 
                                           wtr.isSig == 1))), 
                       k = 1))
```

```{r message=FALSE, warning=FALSE, results='hide'}
reg.ss.vars <- c("rst_nn", "rstrt.isSig.dist","road_nn", "road.isSig.dist","wtr_nn", "wtr.isSig.dist")

## RUN REGRESSIONS
reg.ss.spatialCV_new <- crossValidate(
  dataset = final_net_new,
  id = "uniqueID",                           
  dependentVariable = "countlitter",
  indVariables = reg.ss.vars) %>%
    dplyr::select(uniqueID, countlitter, Prediction, geometry)
```

### Bias Reduction Model Results

The potential issue with litter data is due to quantity and unrecorded amounts. Litter that is recorded and disposed of, despite campaigns and efforts of cleanups, often leave large portions of 'what would be data samples' unaccounted for. In response to this inherent flaw in data collection, our alternative model creates random samples to act as auxiliary litter that, in most likelihood, was unrecorded.  

#### Bias Reduction Model, Mean Absolute Error

The accuracy is almost the same as the one before with slightly more error in this model due to the auxillary datapoints that are similar but not exact in the original dataset. 

```{r, warning=FALSE, message=FALSE, results='hide'}
error_by_reg_and_fold_new <- 
  reg.ss.spatialCV_new %>%
    group_by(uniqueID) %>% 
    summarize(Mean_Error = mean(Prediction - countlitter, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold_new %>% 
  arrange(desc(MAE))

error_by_reg_and_fold_new %>% 
  arrange(MAE)
```

```{r, warning=FALSE, message=FALSE, results='hide'}
error_by_reg_and_fold_new %>% filter(MAE <=10) %>%
  ggplot(aes(MAE)) + 
    geom_histogram(bins = 30, colour="black", fill = "#FDE725FF") +
  scale_x_continuous(breaks = seq(0, 11, by = 1)) + 
    labs(title="Distribution of MAE", subtitle = "LOGO-CV",
         x="Mean Absolute Error", y="Count") 
```

```{r, warning=FALSE, message=FALSE, results='hide'}
ml_breaks_new <- classIntervals(reg.ss.spatialCV_new$Prediction, 
                             n = 5, "fisher")
litter_risk_sf_new <-
  reg.ss.spatialCV_new %>%
  mutate(label = "Risk Predictions",
         Risk_Category =classInt::findCols(ml_breaks_new),
         Risk_Category = case_when(
           Risk_Category == 5 ~ "5th",
           Risk_Category == 4 ~ "4th",
           Risk_Category == 3 ~ "3rd",
           Risk_Category == 2 ~ "2nd",
           Risk_Category == 1 ~ "1st")) %>%
  cbind(
    aggregate(
      dplyr::select(allrandom_points_df) %>% mutate(litterCount = 1), ., sum) %>%
      mutate(litterCount = replace_na(litterCount, 0))) %>%
  dplyr::select(label,Risk_Category, litterCount)
```

#### Bias Reduction Model Prediction 

We see similar results as from the first model further proving the integrity of the data evaluated prior. Despite the additional data points that are meant to spread out the evaluation, we see a circular shape forming on the central north section adjacent to the edge. Because the boundary (water) is on the east, and there is litter developing an encirclement, the model detect the potential for litter to most likely occur within that circle. After all, restaurants are present in the 'category 5' area just as much as the surroundings, yet no litter was recorded there. These results bring hope to our model's capabilities in advancing Urban Ocean's goals as it aims to assess litter accumulation in cities around the world. 

```{r}
ggplot() +
    geom_sf(data = litter_risk_sf_new, aes(fill = Risk_Category), colour = NA) +
    geom_sf(data = allrandom_points_df, size = .01,alpha = 0.01, colour = "red") +
    scale_fill_viridis(discrete = TRUE) +
    labs(title="Litter Risk Predictions, Chennai",
         subtitle="") +
    mapTheme(title_size = 14)
```

# Attempt at Random Forest Model

To be continued. 

```{r}
buildRFModel <- function(dataset, dependentVariable, indVariables, 
                         testFraction = 0.2, ntree = 500, mtry = NULL, nodesize = 1) {
  # Split dataset into training and testing sets
  set.seed(123) # For reproducibility
  total_rows <- nrow(dataset)
  test_rows <- sample(1:total_rows, size = floor(total_rows * testFraction))
  
  train_set <- dataset[-test_rows, ]
  test_set <- dataset[test_rows, ]
  
  # Fit Random Forest model
  rfModel <- randomForest(x = train_set[indVariables], 
                          y = train_set[[dependentVariable]], 
                          ntree = ntree, 
                          mtry = mtry, 
                          nodesize = nodesize)
  
  # Make predictions on the test set
  predictions <- predict(rfModel, newdata = test_set[indVariables])
  
  # Evaluate model performance
  actual <- test_set[[dependentVariable]]
  
  # Example of a simple evaluation metric: Mean Squared Error (MSE)
  mse <- mean((predictions - actual) ^ 2)
  
  cat("Model MSE:", mse, "\n")
  
  return(list(model = rfModel, mse = mse))
}
```

```{r eval=FALSE, include=FALSE}
reg.ss.vars <- c("rst_nn", "rstrt.isSig.dist","road_nn", "road.isSig.dist","wtr_nn", "wtr.isSig.dist")

## RUN REGRESSIONS
reg.ss.spatialCV_new <- rf_cv(
  dataset = final_net_new,
  id = "uniqueID",                           
  dependentVariable = "countlitter",
  indVariables = reg.ss.vars) %>%
    dplyr::select(uniqueID, countlitter, Prediction, geometry)
```

```{r eval=FALSE, include=FALSE}
chen_bd <- c(80.4301860, 13.2436939, 80.1101860, 12.8236939)
chen_sub_bd <- c(80.4301860, 13.1536939, 80.2601860, 12.9136939)

coordinates <- matrix(c(80.2601860, 12.9136939,  # Point 1
                        -74.0060, 40.7528,  # Point 2
                        -73.9860, 40.7528,  # Point 3
                        -73.9860, 40.7128,  # Point 4
                        -74.0060, 40.7128), # Closing point to complete the polygon (same as Point 1)
                      ncol = 2, byrow = TRUE)

# Create a POLYGON geometry
polygon_geometry <- st_polygon(list(coordinates))

# Convert to an sf object
polygon_sf <- st_sfc(polygon_geometry, crs = 4326) 
```

```{r eval=FALSE, include=FALSE}
fishnet_new <- 
  st_make_grid(chen_bdry,
               cellsize = 500, 
               square = TRUE) %>%
  .[chen_bdry] %>%            
  st_sf() %>%
  mutate(uniqueID = 1:n())


litter_net_new <- 
  dplyr::select(litter_p) %>% 
  mutate(countlitter = 1) %>% 
  aggregate(., fishnet_new, sum) %>%
  mutate(countlitter = replace_na(countlitter, 0),
         uniqueID = 1:n(),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

ggplot() +
  geom_sf(data = litter_net_new, aes(fill = countlitter), color = NA) +
  scale_fill_viridis() +
  labs(title = "Count of Litter for the fishnet") +
  mapTheme()
```
