---
title: "function_uo"
author: "Tianxiao"
date: "2024-02-22"
output: html_document
---
# environment setting

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install.packages("remotes")
#remotes::install_github("IREA-CNR-MI/sprawl")

library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(classInt)
library(RCurl)
library(httr)
library(osmdata)
library(randomForest)
#library(tidygraph)
library(XML)
library(neuralnet)
library(MASS)
#library(tidymodels)
library(brms)
library(jsonlite)
library(QuickJSR)
library(hash)

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
source('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/function_UO.R')
st_c    <- st_coordinates
st_coid <- st_centroid

#lists!
cities <- c("Bangkok", "Can_Tho", "Chennai", "Melaka", "Mumbai", "Panama_City", 
            "Pune", "Salvador", "Santa_Fe", "Santiago", "Semarang", "Surat")
bd <- c("Bangkok_bd", "Can_Tho_bd", "Chennai_bd", "Melaka_bd", "Mumbai_bd", "Panama_City_bd", "Pune_bd", "Salvador_bd", "Santa_Fe_bd", "Santiago_bd", "Semarang_bd", "Surat_bd")
bdM <- c("Bangkok_bdM", "Can_Tho_bdM", "Chennai_bdM", "Melaka_bdM", "Mumbai_bdM", "Panama_City_bdM","Pune_bdM", "Salvador_bdM", "Santa_Fe_bdM", "Santiago_bdM", "Semarang_bdM", "Surat_bdM")

# pre-store of osm data need to use 
# a more expandable version of function
# the actual store order is cate label, small cate
stor_df <- data.frame(cato = character(), small =list(), label = character(),stringsAsFactors = FALSE)
add_row <-function(cato,small,label){
  new_row <- list(cato = cato, small = small, label = label)
  stor_df <- bind_rows(stor_df, new_row)
  return(stor_df)
}
stor_df <- add_row('water',list(c('canal','drain','ditch')), 'water')
stor_df <- add_row('amenity',list(c('waste_basket','waste_disposal','waste_transfer_station','recycling')), 'waste')
stor_df <- add_row('amenity',list(c('restaurant','pub','bar')), 'restaurant')
stor_df <- add_row('highway',list('residential'), 'road')
stor_df <- add_row('landuse',list('industrial'), 'industrial')
stor_df <- add_row('landuse',list('residential'), 'residential')
stor_df <- add_row('landuse',list('retail'), 'retail')
```

# Load data

```{r multi-city}

# load_city_data: load any mdt data file in the repository, can be applied ot a list
# input of function:
# city: name of city

load_city_data <- function(city) {
  url <- paste0("https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/mdt-data", city, ".csv")
  data <- read_csv(url)
  
  # Convert latitude and longitude columns to numeric
  data$latitude <- as.numeric(data$latitude)
  data$longitude <- as.numeric(data$longitude)
  
  # Create spatial object
  data_sf <- st_as_sf(data, coords = c("longitude", "latitude"), crs = 4326)
  
  return(data_sf)
}

# load_city_kml:
# input of function:
# city: name of city

load_city_kml <- function(city) {
  kml_url <- paste0("https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/", city, ".kml")
  kml_data <- st_read(kml_url)%>%
    st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")
  return(kml_data)
}

# load_city_kml_meter:
# input of function:
# city: name of city

load_city_kml_meter <- function(city) {
  kml_url <- paste0("https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/", city, ".kml")
  kml_data <- st_read(kml_url) %>%
    st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant") %>%
    st_transform('EPSG:32643')
  return(kml_data)
}

city_data_list <- lapply(cities, load_city_data)
names(city_data_list) <- cities

bd_data_list <- lapply(cities, load_city_kml)
names(bd_data_list) <- bd

bd_data_meter_list <- lapply(cities, load_city_kml_meter)
names(bd_data_meter_list) <- bdM


#input: mdt file
final_net <- function(city_litter, bd, bd_meter) {
  litter_p <- city_litter %>%
    filter(master_material == 'PLASTIC') %>%
    st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")
  litter_p <- subset(litter_p, select = -c(event_name, project_name))
  
  #fishnet
  temp_bbox <- get_bbox(bd) 
  temp_fish <- create_fish(bd_meter)
  final_net <- countfishnet(temp_fish, litter_p) 
  final_net <- pn_gen(stor_df) 
  final_net <- moran_gen(final_net,stor_df)
  final_net <- st_transform(final_net, crs = 4326)
  
  return(final_net)
}

for (i in seq_along(city_data_list)) {
  city_litter <- city_data_list[[i]]
  bd <- bd_data_list[[i]]
  bd_meter <- bd_data_meter_list[[i]]
  
  litter_p <- city_litter %>%
    filter(master_material == 'PLASTIC') %>%
    st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")
  litter_p <- subset(litter_p, select = -c(event_name, project_name))
  
  #fishnet
  temp_bbox <- get_bbox(bd) 
  temp_fish <- create_fish(bd_meter)
  final_net <- countfishnet(temp_fish, litter_p) 
  final_net <- pn_gen(stor_df) 
  Sys.sleep(2)
  final_net <- moran_gen(final_net,stor_df)
  Sys.sleep(5)
  final_net <- st_transform(final_net, crs = 4326)
  
  final_net_list[[i]] <- final_net
}

litter_p <- city_data_list[[3]] %>%
    filter(master_material == 'PLASTIC') %>%
    st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")
  litter_p <- subset(litter_p, select = -c(event_name, project_name))
  
  #fishnet
temp_bbox <- get_bbox(bd_data_list[[3]]) 
temp_fish <- create_fish(bd_data_meter_list[[3]])
final_net <- countfishnet(temp_fish, city_data_list[[3]]) 
final_net <- pn_gen(stor_df) 
final_net <- moran_gen(final_net,stor_df)
  final_net <- st_transform(final_net, crs = 4326)
  
  return(final_net)



final_net_list <- mapply(final_net, city_data_list, bd_data_list, bd_data_list, SIMPLIFY = FALSE)

test <- final_net(city_data_list[[3]], bd_data_list[[3]], bd_data_meter_list[[3]])

city_data_list[[3]]

str(city_data_list[[1]])
print(st_bbox(city_data_list[[1]]))


list2env(final_net_list, envir = .GlobalEnv)

#and then we can rbind later if we want :)

for (i in seq_along(bd_data_list)) {
  bbox <- st_bbox(bd_data_list[[i]])
  cat("Bounding box for", names(bd_data_list)[i], ":\n")
  print(bbox)
}

```


```{r chennai data}
#step to load city's data
litter <- read.csv('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/mdt-dataChennai.csv')

# data filter and projection transformation
litter_p <- litter%>%
  filter(master_material == 'PLASTIC')%>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")%>%
  st_transform('EPSG:32643')

img <- raster("/Users/mr.smile/Desktop/UPENN/Spring24/CPLN790/data/population_ind_pak_general/population_10_lon_80_general-v1.5.tif")

chen_bdry <- st_read('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/gcc-divisions-latest.kml')
chen_bdry <- st_set_crs(chen_bdry, 4326)%>%
  st_transform('EPSG:32643')

temp_bd <- st_read('/Users/mr.smile/Desktop/UPENN/Spring24/CPLN790/data/archive (1)/cma_layer.shp')

temp_bbox <- get_bbox(temp_bd) # get the bounding box (the projection of temp_bd should be epsg4326)
temp_fish <- create_fish(chen_bdry) # get the fishnet of the city (the projection of chen_bdry should be meter degree)
final_net <- countfishnet(temp_fish, litter_p) # create base fishnet with litter (also the one used as final one)
final_net <- pn_gen(stor_df) # add osm point data and knn calculation result into the final dataset
#temp_point <- raster_process(img,temp_bd) # convert the raster file to point one 
#pop_result <- pop_process(temp_point, temp_fish, 32643) # summary the population result
#final_net <- add_pop(pop_result,final_net) # add the pop result into the final dataset
final_net <- moran_gen(final_net,stor_df) # calculate the moran's I result into the dataset
# DONE!
chen_net <- final_net
```

```{r bangkok data}
litter <- read.csv('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/mdt-dataBangkok.csv')

litter_p <- litter%>%
  filter(master_material == 'PLASTIC')%>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")%>%
  st_transform('EPSG:32643')
litter_p <- subset(litter_p, select = -c(event_name, project_name))

bok_bdry <- st_read('https://github.com/TrevorKap/MUSA810-Marine-Pollution/raw/main/Data/Bangkok.kml')
bok_bdry <- st_set_crs(bok_bdry, 4326)%>%
  st_transform('EPSG:32643')

bok_bd <- st_read('https://github.com/TrevorKap/MUSA810-Marine-Pollution/raw/main/Data/Bangkok.kml')

temp_bbox <- get_bbox(bok_bd) 
temp_fish <- create_fish(bok_bdry)
final_net <- countfishnet(temp_fish, litter_p) 
final_net <- pn_gen(stor_df) 
final_net <- moran_gen(final_net,stor_df)
bok_net <- final_net
```

```{r santiago data}
litter <- read.csv('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/mdt-dataSantiago.csv')

# data filter and projection transformation
litter_p <- litter%>%
  filter(master_material == 'PLASTIC')%>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")%>%
  st_transform('EPSG:32643')
litter_p <- subset(litter_p, select = -c(event_name, project_name))

# load boundary data
## ATTENTION! this part should be the boundry of YOUR CITY
san_bdry <- st_read('https://github.com/TrevorKap/MUSA810-Marine-Pollution/raw/main/Data/Santiago.kml')
san_bd <- san_bdry
san_bdry <- st_set_crs(san_bdry, 4326)%>%
  st_transform('EPSG:32643')

temp_bbox <- get_bbox(san_bd) 
temp_fish <- create_fish(san_bdry)
final_net <- countfishnet(temp_fish, litter_p) 
final_net <- pn_gen(stor_df) 
final_net <- moran_gen(final_net,stor_df)
san_net <- final_net
```

```{r}
chen_net <- chen_net %>%
  dplyr::select(!c(avg_pop,sum_pop))%>%
  mutate(city = 'Chennai',
         country = 'India')

san_net <- san_net %>%
  mutate(city = 'Santiago',
         country = 'Chile')

bok_net <- bok_net %>%
  mutate(city = 'Bangkok',
         country = 'Thailand')

tt_net <- rbind(chen_net,san_net,bok_net)

# reference: https://wiki.openstreetmap.org/wiki/Map_features#Entertainment,_Arts_&_Culturee 
leisure <- c('park')
act <- c('maxspeed') 
```

# SHOULD BE PCA

# Model part
```{r}
reg.ss.vars <- c("restaurant_nn", "rst_sig_dis","road_nn", "road_sig_dis","watr_nn", "wtr_sig_dis",'sum_pop') # the independent variables included

## RUN REGRESSIONS
reg.ss.spatialCV <- crossValidate(
  dataset = final_net,
  id = "uniqueID",                           
  dependentVariable = "count", # this count is the litter count 
  indVariables = reg.ss.vars) %>%
    dplyr::select(uniqueID, count, Prediction, geometry)
```

```{r}
error_visual(reg.ss.spatialCV) # visualize the MSE of prediction
```

```{r}
risk_visualize(reg.ss.spatialCV,litter_p) # visualize the risk map
```

```{r}
df_model <- st_drop_geometry(final_net)%>%dplyr::select(!cvID)

temp.rf <- randomForest(count ~ ., data = df_model%>%dplyr::select(!uniqueID), mtry = 10,ntree=70, 
                         importance = TRUE, na.action = na.omit) 

temp.lr <- glm(count ~ ., data = df_model%>%dplyr::select(!uniqueID),family = "poisson", na.action = na.omit) 

temp.lr.qs <- glm(count ~ ., data = df_model%>%dplyr::select(!uniqueID),family = "quasi", na.action = na.omit) 

temp.lr.qp <- glm(count ~ ., data = df_model%>%dplyr::select(!uniqueID),family = "quasipoisson", na.action = na.omit) 

nn_model = neuralnet(count ~ .,data=df_model%>%dplyr::select(!uniqueID),hidden=c(5,2),
linear.output = TRUE
)
```

```{r}
fit.1<- brm(count~ ., data=df_model%>%dplyr::select(!uniqueID), family=gaussian(),
              warmup=500, #burnin for 500 interations for each chain = 1000 burnin
              iter=1000, chains=2, #2*1000 =2000 - 1000 burnin = 1000 total iterations
              cores=2,seed = 1115) #number of computer cores, 1 per chain is good.
```

```{r}
df_brm_rst <- model_process(df_model,fit.1)
df_brm_r <- model_result(df_model,fit.1) %>%mutate(model = 'BRM')
df_brm_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_brm_rst, by="uniqueID")

estimates_list <- list()
# Iterate over each row by index
for(i in 1:nrow(df_brm_rst)) {
  # Extract the 'Prediction' for the current row
  current_prediction <- df_brm_rst$Prediction[[i]][1]
  estimates_list[[i]] <- current_prediction
}

df_brm_rst$Estimate <- estimates_list
df_brm_rst <- df_brm_rst %>%
  dplyr::select(uniqueID,count,geometry,Estimate)%>%
  rename(Prediction = Estimate)

df_brm_rst$Prediction <- as.numeric(unlist(df_brm_rst$Prediction))

grid.arrange(risk_v(df_brm_rst,litter_p,"kmeans"),
             visual_count_net(water_net,water_point,chen_bdry,'water'),nrow=2)
```

```{r}
# the model only use fishnet having data
temp_net <- final_net %>%
  filter(count != 0)

temp_model <- st_drop_geometry(temp_net)%>%dplyr::select(!cvID)

temp.rf_s <- randomForest(count ~ ., data = temp_model%>%dplyr::select(!uniqueID), mtry = 10,ntree=70, 
                         importance = TRUE, na.action = na.omit) 

temp.lr_s <- glm(count ~ ., data = temp_model%>%dplyr::select(!uniqueID),family = "poisson", na.action = na.omit) 

temp.lr.qs_s <- glm(count ~ ., data = temp_model%>%dplyr::select(!uniqueID),family = "quasi", na.action = na.omit) 

temp.lr.qp_s <- glm(count ~ ., data = temp_model%>%dplyr::select(!uniqueID),family = "quasipoisson", na.action = na.omit) 

nn_model_s = neuralnet(count ~ .,data=temp_model%>%dplyr::select(!uniqueID),hidden=c(5,2),
linear.output = TRUE
)
```

```{r}
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
train_data <- training(data_split)
test_data <- testing(data_split)

# Create a decision tree model specification
tree_spec <- decision_tree(mode = "regression", tree_depth = 4,engine = 'rpart') 

# Fit the model to the training data
tree_fit <- tree_spec %>%
 fit(count ~ ., data = train_data)

predictions <- tree_fit %>%
 predict(test_data) %>%
 pull(.pred)

metrics <- metric_set(rmse, rsq)
model_performance <- test_data %>%
 mutate(predictions = predictions) %>%
 metrics(truth = count, estimate = predictions)

print(model_performance)

predictions <- tree_fit %>%
 predict(df_model)%>%
 pull(.pred)

df_dt_rst <- df_model%>%
  mutate(Prediction = predictions)%>%
  dplyr::select(uniqueID,count,Prediction)

df_dt_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_dt_rst, by="uniqueID")

risk_v(df_dt_rst,litter_p,"kmeans")
```

```{r}
df_rf_rst <- model_process(df_model,temp.rf)
df_lr_rst <- model_process(df_model,temp.lr)
df_lrqs_rst <- model_process(df_model,temp.lr.qs)
df_lrqp_rst <- model_process(df_model,temp.lr.qp)
df_nn_rst <- model_process(df_model,nn_model)

df_rf_r <- model_result(df_model,temp.rf) %>%mutate(model = 'RF')
df_lr_r <- model_result(df_model,temp.lr) %>%mutate(model = 'LR')
df_lrqs_r <- model_result(df_model,temp.lr.qs)%>%mutate(model = 'LR_quasi')
df_lrqp_r <- model_result(df_model,temp.lr.qp)%>%mutate(model = 'LR_quasipoisson')
df_nn_r <- model_result(df_model,nn_model)%>%mutate(model = 'Neural Net')
df_r_tt <- do.call("rbind", list(df_rf_r, df_lr_r, df_lrqs_r,df_lrqp_r,df_nn_r))

df_rf_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_rf_rst, by="uniqueID")
df_lr_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_lr_rst, by="uniqueID")
df_lrqs_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_lrqs_rst, by="uniqueID")
df_lrqp_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_lrqp_rst, by="uniqueID")
```

```{r}
# use the model only use fishnet having data to predict the whole area
df_rf_rst_s <- model_process(df_model,temp.rf_s)
df_lr_rst_s <- model_process(df_model,temp.lr_s)
df_lrqs_rst_s <- model_process(df_model,temp.lr.qs_s)
df_lrqp_rst_s <- model_process(df_model,temp.lr.qp_s)
df_nn_rst_s <- model_process(df_model,nn_model_s)

df_rf_r_s <- model_result(df_model,temp.rf_s) %>%mutate(model = 'RF')
df_lr_r_s <- model_result(df_model,temp.lr_s) %>%mutate(model = 'LR')
df_lrqs_r_s <- model_result(df_model,temp.lr.qs_s)%>%mutate(model = 'LR_quasi')
df_lrqp_r_s <- model_result(df_model,temp.lr.qp_s)%>%mutate(model = 'LR_quasipoisson')
df_nn_r_s <- model_result(df_model,nn_model_s)%>%mutate(model = 'Neural Net')
df_r_tt_s <- do.call("rbind", list(df_rf_r_s, df_lr_r_s, df_lrqs_r_s,df_lrqp_r_s,df_nn_r_s))

df_rf_rst_s <- left_join(final_net%>%dplyr::select(uniqueID),df_rf_rst_s, by="uniqueID")
df_lr_rst_s <- left_join(final_net%>%dplyr::select(uniqueID),df_lr_rst_s, by="uniqueID")
df_lrqs_rst_s <- left_join(final_net%>%dplyr::select(uniqueID),df_lrqs_rst_s, by="uniqueID")
df_lrqp_rst_s <- left_join(final_net%>%dplyr::select(uniqueID),df_lrqp_rst_s, by="uniqueID")
```

```{r}
temp <- tt_net %>%
  st_transform('EPSG:4326')

exportJSON <- toJSON(temp)
write(exportJSON, "/Users/mr.smile/Desktop/UPENN/Spring24/CPLN790/test_0401.json")
#write_csv(temp,'/Users/mr.smile/Desktop/UPENN/Spring24/CPLN790/test_new.csv')
```
