stor_df <- bind_rows(stor_df, new_row)
return(stor_df)
}
stor_df <- add_row('water',list(c('canal','drain','ditch')), 'water')
stor_df <- add_row('amenity',list(c('waste_basket','waste_disposal','waste_transfer_station','recycling')), 'waste')
stor_df <- add_row('amenity',list(c('restaurant','pub','bar')), 'restaurant')
stor_df <- add_row('highway',list('residential'), 'road')
stor_df <- add_row('landuse',list('industrial'), 'industrial')
stor_df <- add_row('landuse',list('residential'), 'residential')
stor_df <- add_row('landuse',list('retail'), 'retail')
#step to load city's data
litter <- read.csv('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/mdt-dataChennai.csv')
# data filter and projection transformation
litter_p <- litter%>%
filter(master_material == 'PLASTIC')%>%
st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")%>%
st_transform('EPSG:32643')
img <- raster("https://github.com/TrevorKap/MUSA810-Marine-Pollution/raw/main/Data/rs_img/population_10_lon_80_general-v1.5.tif")
chen_bdry <- st_read('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/gcc-divisions-latest.kml')
knitr::opts_chunk$set(echo = TRUE)
#install.packages("remotes")
#remotes::install_github("IREA-CNR-MI/sprawl")
library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(classInt)
library(RCurl)
library(httr)
library(osmdata)
library(randomForest)
library(tidygraph)
library(XML)
library(neuralnet)
library(MASS)
#library(tidymodels)
library(brms)
library(jsonlite)
library(QuickJSR)
library(hash)
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
source('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/function_UO.R')
st_c    <- st_coordinates
st_coid <- st_centroid
# pre-store of osm data need to use
# a more expandable version of function
# the actual store order is cate label, small cate
stor_df <- data.frame(cato = character(), small =list(), label = character(),stringsAsFactors = FALSE)
add_row <-function(cato,small,label){
new_row <- list(cato = cato, small = small, label = label)
stor_df <- bind_rows(stor_df, new_row)
return(stor_df)
}
stor_df <- add_row('water',list(c('canal','drain','ditch')), 'water')
stor_df <- add_row('amenity',list(c('waste_basket','waste_disposal','waste_transfer_station','recycling')), 'waste')
stor_df <- add_row('amenity',list(c('restaurant','pub','bar')), 'restaurant')
stor_df <- add_row('highway',list('residential'), 'road')
stor_df <- add_row('landuse',list('industrial'), 'industrial')
stor_df <- add_row('landuse',list('residential'), 'residential')
stor_df <- add_row('landuse',list('retail'), 'retail')
#step to load city's data
litter <- read.csv('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/mdt-dataChennai.csv')
# data filter and projection transformation
litter_p <- litter%>%
filter(master_material == 'PLASTIC')%>%
st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")%>%
st_transform('EPSG:32643')
img <- raster("https://github.com/TrevorKap/MUSA810-Marine-Pollution/raw/main/Data/rs_img/population_10_lon_80_general-v1.5.tif")
chen_bdry <- st_read('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/gcc-divisions-latest.kml')
knitr::opts_chunk$set(echo = TRUE)
#install.packages("remotes")
#remotes::install_github("IREA-CNR-MI/sprawl")
library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(classInt)
library(RCurl)
library(httr)
library(osmdata)
library(randomForest)
library(tidygraph)
library(XML)
library(neuralnet)
library(MASS)
#library(tidymodels)
library(brms)
library(jsonlite)
library(QuickJSR)
library(hash)
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
source('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/function_UO.R')
st_c    <- st_coordinates
st_coid <- st_centroid
# pre-store of osm data need to use
# a more expandable version of function
# the actual store order is cate label, small cate
stor_df <- data.frame(cato = character(), small =list(), label = character(),stringsAsFactors = FALSE)
add_row <-function(cato,small,label){
new_row <- list(cato = cato, small = small, label = label)
stor_df <- bind_rows(stor_df, new_row)
return(stor_df)
}
stor_df <- add_row('water',list(c('canal','drain','ditch')), 'water')
stor_df <- add_row('amenity',list(c('waste_basket','waste_disposal','waste_transfer_station','recycling')), 'waste')
stor_df <- add_row('amenity',list(c('restaurant','pub','bar')), 'restaurant')
stor_df <- add_row('highway',list('residential'), 'road')
stor_df <- add_row('landuse',list('industrial'), 'industrial')
stor_df <- add_row('landuse',list('residential'), 'residential')
stor_df <- add_row('landuse',list('retail'), 'retail')
#step to load city's data
litter <- read.csv('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/mdt-dataChennai.csv')
# data filter and projection transformation
litter_p <- litter%>%
filter(master_material == 'PLASTIC')%>%
st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")%>%
st_transform('EPSG:32643')
img <- raster("https://github.com/TrevorKap/MUSA810-Marine-Pollution/raw/main/Data/rs_img/population_10_lon_80_general-v1.5.tif")
chen_bdry <- st_read('https://github.com/TrevorKap/MUSA810-Marine-Pollution/raw/main/Data/archive%20data/gcc-divisions-latest.kml')
chen_bdry <- st_set_crs(chen_bdry, 4326)%>%
st_transform('EPSG:32643')
temp_bd <- st_read('https://github.com/TrevorKap/MUSA810-Marine-Pollution/raw/main/Data/archive%20data/cma_layer.kml')
temp_bbox <- get_bbox(temp_bd) # get the bounding box (the projection of temp_bd should be epsg4326)
temp_fish <- create_fish(chen_bdry) # get the fishnet of the city (the projection of chen_bdry should be meter degree)
final_net <- countfishnet(temp_fish, litter_p) # create base fishnet with litter (also the one used as final one)
final_net <- pn_gen(stor_df) # add osm point data and knn calculation result into the final dataset
#temp_point <- raster_process(img,temp_bd) # convert the raster file to point one
#pop_result <- pop_process(temp_point, temp_fish, 32643) # summary the population result
#final_net <- add_pop(pop_result,final_net) # add the pop result into the final dataset
final_net <- moran_gen(final_net,stor_df) # calculate the moran's I result into the dataset
# DONE!
chen_net <- final_net
litter <- read.csv('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/mdt-dataBangkok.csv')
litter_p <- litter%>%
filter(master_material == 'PLASTIC')%>%
st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")%>%
st_transform('EPSG:32643')
litter_p <- subset(litter_p, select = -c(event_name, project_name))
bok_bdry <- st_read('https://github.com/TrevorKap/MUSA810-Marine-Pollution/raw/main/Data/Bangkok.kml')
bok_bdry <- st_set_crs(bok_bdry, 4326)%>%
st_transform('EPSG:32643')
bok_bd <- st_read('https://github.com/TrevorKap/MUSA810-Marine-Pollution/raw/main/Data/Bangkok.kml')
temp_bbox <- get_bbox(bok_bd)
temp_fish <- create_fish(bok_bdry)
final_net <- countfishnet(temp_fish, litter_p)
final_net <- pn_gen(stor_df)
final_net <- moran_gen(final_net,stor_df)
bok_net <- final_net
litter <- read.csv('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/Data/mdt-dataSantiago.csv')
# data filter and projection transformation
litter_p <- litter%>%
filter(master_material == 'PLASTIC')%>%
st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")%>%
st_transform('EPSG:32643')
litter_p <- subset(litter_p, select = -c(event_name, project_name))
# load boundary data
## ATTENTION! this part should be the boundry of YOUR CITY
san_bdry <- st_read('https://github.com/TrevorKap/MUSA810-Marine-Pollution/raw/main/Data/Santiago.kml')
san_bd <- san_bdry
san_bdry <- st_set_crs(san_bdry, 4326)%>%
st_transform('EPSG:32643')
temp_bbox <- get_bbox(san_bd)
temp_fish <- create_fish(san_bdry)
final_net <- countfishnet(temp_fish, litter_p)
final_net <- pn_gen(stor_df)
final_net <- moran_gen(final_net,stor_df)
san_net <- final_net
chen_net <- chen_net %>%
#dplyr::select(!c(avg_pop,sum_pop))%>%
mutate(city = 'Chennai',
country = 'India')
san_net <- san_net %>%
mutate(city = 'Santiago',
country = 'Chile')
bok_net <- bok_net %>%
mutate(city = 'Bangkok',
country = 'Thailand')
tt_net <- rbind(chen_net,san_net,bok_net)
# reference: https://wiki.openstreetmap.org/wiki/Map_features#Entertainment,_Arts_&_Culturee
leisure <- c('park')
act <- c('maxspeed')
visual_count(chen_net,'waste')
visual_count(chen_net,'water')
visual_count(chen_net,"restaurant")
visual_count(chen_net,'road')
visual_count(chen_net,'industrial')
visual_count(chen_net,"residential")
visual_count(chen_net,'retail')
visual_cotinuous(chen_net,'waste_nn')
visual_cotinuous(chen_net,'water_nn')
visual_cotinuous(chen_net,"restaurant_nn")
visual_cotinuous(chen_net,'road_nn')
visual_cotinuous(chen_net,'industrial_nn')
visual_cotinuous(chen_net,"residential_nn")
visual_cotinuous(chen_net,'retail_nn')
visual_count(chen_net,'waste_sig')
visual_count(chen_net,'water_sig')
visual_count(chen_net,"restaurant_sig")
visual_count(chen_net,'road_sig')
visual_count(chen_net,'industrial_sig')
visual_count(chen_net,"residential_sig")
visual_count(chen_net,'retail_sig')
visual_cotinuous(chen_net,'waste_sig_dis')
visual_cotinuous(chen_net,'water_sig_dis')
visual_cotinuous(chen_net,"restaurant_sig_dis")
visual_cotinuous(chen_net,'road_sig_dis')
visual_cotinuous(chen_net,'industrial_sig_dis')
visual_cotinuous(chen_net,"residential_sig_dis")
visual_cotinuous(chen_net,'retail_sig_dis')
cor_chen <- st_drop_geometry(chen_net) %>% dplyr::select(!c(uniqueID,cvID,city,country))
cor_nor_chen<- scale(cor_chen)
corr_matrix <- cor(cor_nor_chen)
ggcorrplot(corr_matrix,type = 'upper')
cor_chen <- st_drop_geometry(chen_net) %>% dplyr::select(!c(uniqueID,cvID,city,country))
cor_nor_chen<- scale(cor_chen)
corr_matrix <- cor(cor_nor_chen)
ggcorrplot(corr_matrix,type = 'upper')
cor_chen <- st_drop_geometry(chen_net) %>% dplyr::select(!c(uniqueID,cvID,city,country))
cor_nor_chen<- scale(cor_chen)
corr_matrix <- cor(cor_nor_chen)
ggcorrplot(corr_matrix)
cor_chen <- st_drop_geometry(chen_net) %>% dplyr::select(!c(uniqueID,cvID,city,country))
cor_nor_chen<- scale(cor_chen)
corr_matrix <- cor(cor_nor_chen)
ggcorrplot(corr_matrix)
cor_chen <- st_drop_geometry(chen_net) %>% dplyr::select(!c(uniqueID,cvID,city,country))
cor_nor_chen<- scale(cor_chen)
corr_matrix <- cor(cor_nor_chen)
ggcorrplot(corr_matrix)
cor_chen <- st_drop_geometry(chen_net) %>% dplyr::select(!c(uniqueID,cvID,city,country))
cor_nor_chen<- scale(cor_chen)
corr_matrix <- cor(cor_nor_chen)
ggcorrplot(corr_matrix)
cor_chen <- st_drop_geometry(chen_net) %>% dplyr::select(!c(uniqueID,cvID,city,country))
cor_nor_chen<- scale(cor_chen)
corr_matrix <- cor(cor_nor_chen)
#ggcorrplot(corr_matrix)
data.pca <- princomp(corr_matrix)
summary(data.pca)
data.pca$loadings[, 1:2]
fviz_eig(data.pca, addlabels = TRUE)
visual_count(chen_net,'waste')
visual_count(chen_net,'water')
visual_count(chen_net,"restaurant")
visual_count(chen_net,'road')
visual_count(bok_net,'industrial')
visual_count(chen_net,"residential")
visual_count(chen_net,'retail')
visual_cotinuous(chen_net,'waste_nn')
visual_cotinuous(san_net,'water_nn')
visual_cotinuous(san_net,"restaurant_nn")
visual_cotinuous(san_net,'road_nn')
visual_cotinuous(san_net,'industrial_nn')
visual_cotinuous(san_net,"residential_nn")
visual_cotinuous(san_net,'retail_nn')
visual_count(bok_net,'waste_sig')
visual_count(bok_net,'water_sig')
visual_count(bok_net,"restaurant_sig")
visual_count(bok_net,'road_sig')
visual_count(bok_net,'industrial_sig')
visual_count(bok_net,"residential_sig")
visual_count(bok_net,'retail_sig')
visual_cotinuous(bok_net,'waste_sig_dis')
visual_cotinuous(bok_net,'water_sig_dis')
visual_cotinuous(bok_net,"restaurant_sig_dis")
visual_cotinuous(bok_net,'road_sig_dis')
visual_cotinuous(bok_net,'industrial_sig_dis')
visual_cotinuous(bok_net,"residential_sig_dis")
visual_cotinuous(bok_net,'retail_sig_dis')
data.pca <- princomp(corr_matrix)
summary(data.pca)
data.pca$loadings[, 1:2]
fviz_eig(data.pca, addlabels = TRUE)
library(ggplot2)
library(ggcorrplot)
library(fviz)
library(QuickJSR)
library(ggplot2)
library(fastDummies)
install.packages("fastDummies")
library(fastDummies)
library(corrr)
library(ggcorrplot)
library(FactoMineR)
library(factoextra)
data.pca <- princomp(corr_matrix)
summary(data.pca)
data.pca$loadings[, 1:2]
fviz_eig(data.pca, addlabels = TRUE)
fviz_pca_var(data.pca, col.var = "black")
fviz_cos2(data.pca, choice = "var", axes = 1:2)
fviz_pca_var(data.pca, col.var = "cos2",
gradient.cols = c("black", "orange", "green"),
repel = TRUE)
# prepare for model data
df_model <- st_drop_geometry(tt_net)%>%dplyr::select(!cvID)
df_model <- dummy_cols(df_model, select_columns = "city")
df_model <- dummy_cols(df_model, select_columns = "country")
df_model <- df_model %>% dplyr::select(!c(city,country)) %>% mutate(uniqueID = 1:n())
# several model
temp.rf <- randomForest(count ~ ., data = df_model%>%dplyr::select(!uniqueID), mtry = 10,ntree=70,
importance = TRUE, na.action = na.omit)
temp.lr <- glm(count ~ ., data = df_model%>%dplyr::select(!uniqueID),family = "poisson", na.action = na.omit)
temp.lr.qs <- glm(count ~ ., data = df_model%>%dplyr::select(!uniqueID),family = "quasi", na.action = na.omit)
temp.lr.qp <- glm(count ~ ., data = df_model%>%dplyr::select(!uniqueID),family = "quasipoisson", na.action = na.omit)
nn_model = neuralnet(count ~ .,data=df_model%>%dplyr::select(!uniqueID),hidden=c(5,2),
linear.output = TRUE
)
temp.hbr <- fit.1<- brm(count~ ., data=df_model%>%dplyr::select(!uniqueID), family=gaussian(),warmup=500, iter=1000, chains=2,cores=2,seed = 1115)
fit.1<- brm(count~ ., data=df_model%>%dplyr::select(!uniqueID), family=gaussian(),
warmup=500, #burnin for 500 interations for each chain = 1000 burnin
iter=1000, chains=2, #2*1000 =2000 - 1000 burnin = 1000 total iterations
cores=2,seed = 1115) #number of computer cores, 1 per chain is good.
df_brm_rst <- model_process(df_model,fit.1)
df_brm_r <- model_result(df_model,fit.1) %>%mutate(model = 'BRM')
df_brm_rst <- left_join(final_net%>%dplyr::select(uniqueID),df_brm_rst, by="uniqueID")
estimates_list <- list()
# Iterate over each row by index
for(i in 1:nrow(df_brm_rst)) {
# Extract the 'Prediction' for the current row
current_prediction <- df_brm_rst$Prediction[[i]][1]
estimates_list[[i]] <- current_prediction
}
df_brm_rst$Estimate <- estimates_list
df_brm_rst <- df_brm_rst %>%
dplyr::select(uniqueID,count,geometry,Estimate)%>%
rename(Prediction = Estimate)
df_brm_rst$Prediction <- as.numeric(unlist(df_brm_rst$Prediction))
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
library(factoextra)
library(hash)
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(classInt)
library(RCurl)
library(httr)
library(osmdata)
library(randomForest)
library(tidygraph)
library(XML)
library(neuralnet)
library(MASS)
#library(tidymodels)
library(brms)
library(jsonlite)
library(QuickJSR)
library(hash)
library(fastDummies)
library(corrr)
library(ggcorrplot)
library(FactoMineR)
library(factoextra)
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
library(tidymodels)
library(tidymodels)
library(tidymodels)
library(tidymodels)
library(tidymodels)
library(tidymodels)
install.packages("tidymodels")
knitr::opts_chunk$set(echo = TRUE)
#install.packages("remotes")
#remotes::install_github("IREA-CNR-MI/sprawl")
library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(classInt)
library(RCurl)
library(httr)
library(osmdata)
library(randomForest)
library(tidygraph)
library(XML)
library(neuralnet)
library(MASS)
#library(tidymodels)
library(brms)
library(jsonlite)
library(QuickJSR)
library(hash)
library(fastDummies)
library(corrr)
library(ggcorrplot)
library(FactoMineR)
library(factoextra)
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
source('https://raw.githubusercontent.com/TrevorKap/MUSA810-Marine-Pollution/main/function_UO.R')
st_c    <- st_coordinates
st_coid <- st_centroid
# pre-store of osm data need to use
# a more expandable version of function
# the actual store order is cate label, small cate
stor_df <- data.frame(cato = character(), small =list(), label = character(),stringsAsFactors = FALSE)
add_row <-function(cato,small,label){
new_row <- list(cato = cato, small = small, label = label)
stor_df <- bind_rows(stor_df, new_row)
return(stor_df)
}
stor_df <- add_row('water',list(c('canal','drain','ditch')), 'water')
stor_df <- add_row('amenity',list(c('waste_basket','waste_disposal','waste_transfer_station','recycling')), 'waste')
stor_df <- add_row('amenity',list(c('restaurant','pub','bar')), 'restaurant')
stor_df <- add_row('highway',list('residential'), 'road')
stor_df <- add_row('landuse',list('industrial'), 'industrial')
stor_df <- add_row('landuse',list('residential'), 'residential')
stor_df <- add_row('landuse',list('retail'), 'retail')
df_rf_rst <- model_process(df_model,temp.rf)
df_lr_rst <- model_process(df_model,temp.lr)
df_lrqs_rst <- model_process(df_model,temp.lr.qs)
df_lrqp_rst <- model_process(df_model,temp.lr.qp)
df_nn_rst <- model_process(df_model,nn_model)
df_rf_r <- model_result(df_model,temp.rf) %>%mutate(model = 'RF')
df_lr_r <- model_result(df_model,temp.lr) %>%mutate(model = 'LR')
df_lrqs_r <- model_result(df_model,temp.lr.qs)%>%mutate(model = 'LR_quasi')
df_lrqp_r <- model_result(df_model,temp.lr.qp)%>%mutate(model = 'LR_quasipoisson')
df_nn_r <- model_result(df_model,nn_model)%>%mutate(model = 'Neural Net')
df_r_tt <- do.call("rbind", list(df_rf_r, df_lr_r, df_lrqs_r,df_lrqp_r,df_nn_r))
df_rf_rst <- left_join(tt_net%>%dplyr::select(uniqueID,city),df_rf_rst, by="uniqueID")
df_lr_rst <- left_join(tt_net%>%dplyr::select(uniqueID,city),df_lr_rst, by="uniqueID")
df_lrqs_rst <- left_join(tt_net%>%dplyr::select(uniqueID,city),df_lrqs_rst, by="uniqueID")
df_lrqp_rst <- left_join(tt_net%>%dplyr::select(uniqueID,city),df_lrqp_rst, by="uniqueID")
df_rf_c <- df_rf_rst %>% filter(city == 'Chennai')
df_lr_c <- df_lr_rst %>% filter(city == 'Chennai')
df_lrqs_c <- df_lrqs_rst %>% filter(city == 'Chennai')
df_lrqp_c <- df_lrqp_rst %>% filter(city == 'Chennai')
grid.arrange(
risk_v(df_rf_c,litter_p,"kmeans"),
risk_v(df_lr_c,litter_p,"kmeans"),
risk_v(df_lrqs_c,litter_p,"kmeans"),
risk_v(df_lrqp_c,litter_p,"kmeans"), nrow = 2
)
df_rf_b <- df_rf_rst %>% filter(city == 'Bangkok')
df_lr_b <- df_lr_rst %>% filter(city == 'Bangkok')
df_lrqs_b <- df_lrqs_rst %>% filter(city == 'Bangkok')
df_lrqp_b <- df_lrqp_rst %>% filter(city == 'Bangkok')
grid.arrange(
risk_v(df_rf_b,litter_b,"kmeans"),
risk_v(df_lr_b,litter_b,"kmeans"),
risk_v(df_lrqs_b,litter_b,"kmeans"),
risk_v(df_lrqp_b,litter_b,"kmeans"), nrow = 2
)
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
install.packages("tidymodels")
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
library(tidymodels)
.libpaths()
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
set.seed(123)
data_split <- initial_split(df_model, prop = 0.75)
lib.paths()
.libratypaths()
.libPaths()
library(tidymodels)
r.version
version
install.packages(installr)
install.packages("installr")
updateR
updateR()
